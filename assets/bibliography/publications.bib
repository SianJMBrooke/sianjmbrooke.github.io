@inproceedings{10.1145/3706598.3713235,
author = {Brooke, Si\^{a}n},
title = {“Python is for girls!”: Masculinity, Femininity, and Queering Inclusion at Hackathons},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713235},
doi = {10.1145/3706598.3713235},
abstract = {This paper explores how queerness intersects with hackathon culture, reinforcing or challenging its masculine norms. By utilizing autoethnographic insights from seven UK hackathons, it reveals that while queerness is visibly celebrated, inclusion remains conditional—accepted only when it aligns with masculine-coded technical authority. Femininity, regardless of the queer identities of those who embody it, is devalued and associated with lesser technical competence. Beyond social dynamics, gendered hierarchies influence programming tools, roles, and physical environments, embedding exclusion within technical culture. Although gender-fluid expressions like cosplay provide moments of subversion, they remain limited by the masculine framework of hackathons. This study contributes to human-computer interaction and feminist technology studies by showing that queerness alone does not dismantle gendered hierarchies. It advocates for moving beyond visibility to actively challenge masculinized definitions of technical legitimacy, promoting alternative, non-exclusionary models of expertise.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1001},
numpages = {13},
keywords = {gender, hackathons, inclusion, queerness},
location = {
},
series = {CHI '25}
}

@book{haimson2025trans,
  author = {Haimson, Oliver},
  title = {Trans Technologies},
  publisher = {MIT Press},
  year = {2025},
  url = {https://mitpress.mit.edu/9780262551861/trans-technologies/}
}

@inproceedings{10.1007/978-3-031-97207-2_9,
author = {Martinez Pandiani, Delfina S. and Sang, Erik Tjong Kim and Ceolin, Davide},
title = {OnToxKG: An Ontology-Based Knowledge Graph of&nbsp;Toxic Symbols and&nbsp;Their Manifestations},
year = {2025},
isbn = {978-3-031-97206-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-97207-2_9},
doi = {10.1007/978-3-031-97207-2_9},
abstract = {Online toxicity, evolving through complex multimodal items like memes, poses a significant challenge. Integrating expert knowledge into moderation systems is increasingly crucial for identifying the nuances of toxic symbology, particularly in memes. Despite the wealth of available expertise, its structured integration into automated systems for online content interpretation remains underdeveloped. This paper introduces the OnTox ontology and OnToxKG Knowledge Graph to address gaps in addressing online toxic symbology. OnTox defines the multimodal semantics of 799 potentially toxic symbols. OnToxKG, a multimodal knowledge graph, integrates these symbols with commonsense sources like Wikidata and WordNet. We demonstrate the practical applications of these resources in automatically analyzing meme toxicity.[inline-graphic not available: see fulltext]},
booktitle = {Web Engineering: 25th International Conference, ICWE 2025, Delft, The Netherlands, June 30 – July 3, 2025, Proceedings},
pages = {119–127},
numpages = {9},
keywords = {ontology, toxicity, hate speech, symbology, memetics},
location = {Delft, The Netherlands}
}

@article{10.1145/3274357,
author = {Keyes, Os},
title = {The Misgendering Machines: Trans/HCI Implications of Automatic Gender Recognition},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CSCW},
url = {https://doi.org/10.1145/3274357},
doi = {10.1145/3274357},
abstract = {Automatic Gender Recognition (AGR) is a subfield of facial recognition that aims to algorithmically identify the gender of individuals from photographs or videos. In wider society the technology has proposed applications in physical access control, data analytics and advertising. Within academia, it is already used in the field of Human-Computer Interaction (HCI) to analyse social media usage. Given the long-running critiques of HCI for failing to consider and include transgender (trans) perspectives in research, and the potential implications of AGR for trans people if deployed, I sought to understand how AGR and HCI understand the term "gender", and how HCI describes and deploys gender recognition technology. Using a content analysis of papers from both fields, I show that AGR consistently operationalises gender in a trans-exclusive way, and consequently carries disproportionate risk for trans people subject to it. In addition, I use the dearth of discussion of this in HCI papers that apply AGR to discuss how HCI operationalises gender, and the implications that this has for the field's research. I conclude with recommendations for alternatives to AGR, and some ideas for how HCI can work towards a more effective and trans-inclusive treatment of gender.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {88},
numpages = {22},
keywords = {automatic gender recognition, gender, machine learning, transgender}
}

@article{sosto2024queerbench,
  title        = {{QueerBench}: Quantifying Discrimination in Language Models Toward Queer Identities},
  author       = {Sosto, Mae and Barr{\'o}n-Cede{\~n}o, Alberto},
  year         = {2024},
  archivePrefix= {arXiv},
  eprint       = {2406.12399},
  primaryClass = {cs.CL},
  doi          = {10.48550/arXiv.2406.12399},
  url          = {https://arxiv.org/abs/2406.12399},
  journal      = {arXiv preprint arXiv:2406.12399}
}
